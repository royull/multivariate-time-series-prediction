{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear method makes use of the log backward return (log price difference) to predict foward return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training:\n",
    "1) Ridge regression: on 30 features\n",
    "2) PC regression: pca on 30 features then perform ols\n",
    "\n",
    "Feature: 10 stocks, each with 3 backward return (say, 3min, 7min, 10min, see correlation to decide)\n",
    "\n",
    "Response: 10 stocks' 30min forward return. \n",
    "\n",
    "Groups: [1,4,5,6,8],[0,2,3,7,9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "log_pr = pd.read_pickle(\"../data/log_price.df\")\n",
    "volu = pd.read_pickle(\"../data/volume_usd.df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_format(df):\n",
    "    df_= df.reset_index(level=['stock']).sort_index()\n",
    "    df_ = df_.pivot(columns ='stock')\n",
    "    df_.columns = df_.columns.get_level_values(0) + '_' +  [str(x) for x in df_.columns.get_level_values(1)]\n",
    "\n",
    "    return df_\n",
    "\n",
    "def rsi(close_delta, periods=20, ema=True):\n",
    "    \"\"\"\n",
    "    Returns a pd.Series with the relative strength index.\n",
    "    \"\"\"\n",
    "    close_delta = close_delta.diff()\n",
    "\n",
    "    # Make two series: one for lower closes and one for higher closes\n",
    "    up = close_delta.clip(lower=0)\n",
    "    down = -1 * close_delta.clip(upper=0)\n",
    "    \n",
    "    if ema == True:\n",
    "\t    # Use exponential moving average\n",
    "        ma_up = up.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n",
    "        ma_down = down.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n",
    "    else:\n",
    "        # Use simple moving average\n",
    "        ma_up = up.rolling(window = periods, adjust=False).mean()\n",
    "        ma_down = down.rolling(window = periods, adjust=False).mean()\n",
    "        \n",
    "    rsi = ma_up / ma_down\n",
    "    rsi = 100 - (100/(1 + rsi))\n",
    "    return rsi\n",
    "\n",
    "def get_feature_train(log_pr, volu, x_begin_idx, x_end_idx, y_begin_idx, \n",
    "                        grp_idx=None, rm_outlier=False, print_cor=True):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    log_pr (pdSeries): train set\n",
    "    volu (pdSeries): train set\n",
    "    x_begin_idx (pdIndex): to truncate the NaNs\n",
    "    grp_idx (dict): key is group idx, value is list of stock idx\n",
    "\n",
    "    Returns:\n",
    "    feature_dict (dict): key is group idx, value is a tuple of feature matrix and response\n",
    "    \"\"\"\n",
    "\n",
    "    log_pr_df = log_pr.reset_index().melt(id_vars=['timestamp'])\n",
    "    log_pr_df.columns = ['timestamp', 'stock', 'log_pr']\n",
    "    log_pr_df = log_pr_df.set_index(['timestamp', 'stock']).sort_index()\n",
    "\n",
    "    volu_df = volu.reset_index().melt(id_vars=['timestamp'])\n",
    "    volu_df.columns = ['timestamp', 'stock', 'volu']\n",
    "    volu_df = volu_df.set_index(['timestamp', 'stock']).sort_index()\n",
    "\n",
    "    features = pd.DataFrame(index=log_pr_df.index)\n",
    "\n",
    "    # log_pr feature\n",
    "    for i in [20, 30]:\n",
    "        features['log_pr_{}'.format(i)] = -log_pr_df.groupby(level='stock').log_pr.diff(i)\n",
    "\n",
    "    # # EMA\n",
    "    # ema = lambda x: x.ewm(span=i).mean()\n",
    "    # for i in [10, 30, 50]:\n",
    "    #     features['pr_ema_{}'.format(i)] = log_pr_df.groupby(level='stock').log_pr.apply(ema)\n",
    "\n",
    "    # # MA\n",
    "    # for i in [10, 30, 50]:\n",
    "    #     ma = lambda x: x.rolling(i).mean()\n",
    "    #     features['pr_ma_{}'.format(i)] = log_pr_df.groupby(level='stock').apply(ma)\n",
    "\n",
    "    k_period = 40\n",
    "    d_period = 3\n",
    "    ma_max = lambda x: x.rolling(k_period).max()\n",
    "    ma_min = lambda x: x.rolling(k_period).min()\n",
    "    mad = lambda x: x.rolling(d_period).mean()\n",
    "    msd = lambda x: x.rolling(d_period).sum()\n",
    "\n",
    "    features['pr_min_40'] = log_pr_df.groupby(level='stock').log_pr.apply(ma_min)\n",
    "    features['pr_max_40'] = log_pr_df.groupby(level='stock').log_pr.apply(ma_max)\n",
    "\n",
    "    features['pr_so_40'] = (log_pr_df.log_pr - features['pr_min_40'])*100 / (features['pr_max_40'] - features['pr_min_40'])\n",
    "    features['pr_so_40d3'] = features.groupby(level='stock').pr_so_40.apply(mad)\n",
    "\n",
    "    # STD of log price\n",
    "    for i in [30]:\n",
    "        std = lambda x: x.rolling(i).std()\n",
    "        features['log_pr_std_{}'.format(i)] = log_pr_df.groupby(level='stock').log_pr.apply(std)\n",
    "\n",
    "    # RSI\n",
    "    # features['rsi_20'] = log_pr_df.groupby(level='stock').log_pr.apply(rsi)\n",
    "    features['rsi_30'] = log_pr_df.groupby(level='stock').log_pr.apply(rsi, periods=30)\n",
    "    # features['rsi_50'] = log_pr_df.groupby(level='stock').log_pr.apply(rsi, periods=50)\n",
    "\n",
    "    # volume feature\n",
    "    log_fn = lambda x: np.log(x+1)\n",
    "    features['log_volu'] = volu_df.groupby(level='stock').volu.apply(log_fn)\n",
    "\n",
    "    # stdised volume in 2 hours backward rolling windows\n",
    "    zscore_fn = lambda x: (x - x.rolling(window=30, min_periods=20).mean()) / x.rolling(window=240, min_periods=20).std()\n",
    "    features['volu_z_score'] = volu_df.groupby(level='stock').volu.apply(zscore_fn)\n",
    "\n",
    "    # # Chaikin's money flow\n",
    "    # features['mf_40'] = volu_df.volu * ((2*log_pr_df.log_pr - features['pr_min_40'])\n",
    "    #                             / (features['pr_max_40'] - features['pr_min_40']))\n",
    "    # features['mf_40_ma'] = (features.groupby(level='stock').mf_40.apply(msd) / \n",
    "    #                         volu_df.groupby(level='stock').volu.apply(msd))\n",
    "\n",
    "    # feature_dropped = features.iloc[x_begin_idx:x_end_idx]\n",
    "    response = log_pr.diff(30)\n",
    "    # print(features.shape)\n",
    "    # print(feature_dropped.shape)\n",
    "    # print(response_dropped.shape)\n",
    "\n",
    "    if grp_idx is not None:\n",
    "        feature_dict = {}\n",
    "        for key, idx_lis in grp_idx.items():\n",
    "            feature_df_dropped = wide_format(features.loc[pd.IndexSlice[:,idx_lis],:])\n",
    "            # transform back to wide format\n",
    "            feature_dict[key] = (feature_df_dropped.iloc[x_begin_idx:x_end_idx], \n",
    "                                            response[idx_lis].iloc[y_begin_idx:])\n",
    "        return feature_dict\n",
    "    else:\n",
    "        # transform back to wide format\n",
    "        feature_df_dropped = wide_format(features).iloc[x_begin_idx:x_end_idx]\n",
    "        # feature_df_dropped = feature_df[x_begin_idx:x_end_idx]\n",
    "    \n",
    "        if print_cor:\n",
    "            for i in range(10):\n",
    "                \n",
    "                feature_train_0 = features.xs(i, level='stock').iloc[x_begin_idx:x_end_idx]\n",
    "                print(feature_train_0.corrwith(response[i]))\n",
    "                print(feature_train_0.isnull().sum())\n",
    "\n",
    "        return feature_df_dropped, response.iloc[y_begin_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_idx = {i: [i] for i in range(10)}\n",
    "\n",
    "x_begin_idx = 41\n",
    "x_end_idx = -30\n",
    "y_begin_idx = 71\n",
    "\n",
    "train_split_t = log_pr.index[-87841]\n",
    "#vali_split_t = log_pr.index[-44641]\n",
    "\n",
    "train_feature_dict = get_feature_train(log_pr[:train_split_t], volu[:train_split_t], x_begin_idx, x_end_idx, y_begin_idx,\n",
    "                                        grp_idx=grp_idx, print_cor=False)\n",
    "\n",
    "test_feature_dict = get_feature_train(log_pr[train_split_t:], volu[train_split_t:], x_begin_idx, x_end_idx, y_begin_idx,\n",
    "                                        grp_idx=grp_idx,print_cor=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.regression.linear_model import OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection with AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import itertools as it\n",
    "\n",
    "def forward_regression(X, y):\n",
    "    '''\n",
    "    Input\n",
    "    X,y: training matrix (without intercept)\n",
    "    Return\n",
    "    model: ols model fitted with intercept on the selected features\n",
    "    feature_selected: selected features\n",
    "    '''\n",
    "    initial_list = []\n",
    "    included = list(initial_list)\n",
    "    feature_num = len(X.columns)\n",
    "    best_aics = pd.Series(index={i for i in range(feature_num)})\n",
    "    best_features = list(it.repeat([],feature_num))\n",
    "    for k in range(feature_num):\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_aic = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_aic[new_column] = model.aic\n",
    "        best_aic = new_aic.min()\n",
    "        best_aics[k] = best_aic\n",
    "        best_feature = new_aic.idxmin()\n",
    "        included.append(best_feature)\n",
    "        best_features[k] = included.copy()\n",
    "    feature_selected = best_features[best_aics.idxmin()]\n",
    "    model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[feature_selected]))).fit()\n",
    "    return model,feature_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain0, ytrain0 = train_feature_dict[0]\n",
    "xtest0, ytest0 = test_feature_dict[0]\n",
    "ytrain0 = ytrain0.set_index(xtrain0.index)\n",
    "ytest0 = ytest0.set_index(xtest0.index)\n",
    "reg0,feature0 = forward_regression(xtrain0,ytrain0)\n",
    "reg0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['log_pr_20_0', 'log_pr_30_0', 'pr_min_40_0', 'pr_max_40_0',\n",
       "       'pr_so_40_0', 'pr_so_40d3_0', 'log_pr_std_30_0', 'rsi_30_0',\n",
       "       'log_volu_0', 'volu_z_score_0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain0.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function for the ten stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_OLS(feature_dict):\n",
    "    mod_dict = {}\n",
    "    for i, (X, y) in feature_dict.items():\n",
    "        mod_dict[i] = OLS(y.values, X.values).fit()\n",
    "\n",
    "    return mod_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dict = train_OLS(train_feature_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"models.pckl\", \"wb\") as f:\n",
    "    for model in mod_dict.values():\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_format_test(df):\n",
    "    df_= df.reset_index()\n",
    "    df_ = df_.pivot(columns ='index').apply(lambda s: s.dropna().reset_index(drop=True))\n",
    "    df_.columns = df_.columns.get_level_values(0) + '_' +  [str(x) for x in df_.columns.get_level_values(1)]\n",
    "\n",
    "    return df_\n",
    "\n",
    "def get_feature_test(log_pr, volu, grp_idx=None):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    log_pr (pdSeries): 1 day of log pr \n",
    "    volu (pdSeries): 1 day of volume\n",
    "\n",
    "    Output:\n",
    "    test data frame\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame(index=log_pr.columns)\n",
    "\n",
    "    # backward return\n",
    "    # print(-(log_pr.iloc[-1] - log_pr.iloc[-30]).values)\n",
    "    for i in [10, 20, 30]:\n",
    "        features['log_pr_{}'.format(i)] = -(log_pr.iloc[-1] - log_pr.iloc[-i]).values\n",
    "    # backward rolling std\n",
    "    features['log_pr_std_10'] = log_pr.iloc[-10:].std(0).values\n",
    "    \n",
    "    # volume features\n",
    "    features['log_volu'] = np.log(volu.iloc[-1].values + 1)\n",
    "    features['volu_z_score'] = ((volu.iloc[-1] - volu.iloc[-240:].mean())/volu.iloc[-240:].std()).values\n",
    "\n",
    "    if grp_idx is None:\n",
    "        return wide_format_test(features)\n",
    "    else:\n",
    "        df_dict = {}\n",
    "        for key, idx_lis in grp_idx.items():\n",
    "            df_dict[key] = wide_format_test(features.loc[idx_lis])\n",
    "        return df_dict\n",
    "\n",
    "# def get_feature_test(log_pr, volu, grp_idx=None):\n",
    "#     \"\"\"\n",
    "#     Input: \n",
    "#     log_pr (pdSeries): 1 day of log pr \n",
    "#     volu (pdSeries): 1 day of volume\n",
    "\n",
    "#     Output:\n",
    "#     test data frame\n",
    "#     \"\"\"\n",
    "#     features = pd.DataFrame(index=log_pr.columns)\n",
    "\n",
    "#     # backward return\n",
    "#     # print(-(log_pr.iloc[-1] - log_pr.iloc[-30]).values)\n",
    "#     #for i in [10, 20, 30]:\n",
    "#     #    features['log_pr_{}'.format(i)] = -(log_pr.iloc[-1] - log_pr.iloc[-i]).values\n",
    "#     features['log_pr_{}'.format(30)] = -(log_pr.iloc[-1] - log_pr.iloc[-30]).values\n",
    "#     # backward rolling std\n",
    "#     features['log_pr_std_10'] = log_pr.iloc[-10:].std(0).values\n",
    "    \n",
    "#     # volume features\n",
    "#     features['log_volu'] = np.log(volu.iloc[-1].values + 1)\n",
    "#     features['volu_z_score'] = ((volu.iloc[-1] - volu.iloc[-240:].mean())/volu.iloc[-240:].std()).values\n",
    "\n",
    "#     if grp_idx is None:\n",
    "#         return wide_format_test(features)\n",
    "#     else:\n",
    "#         df_dict = {}\n",
    "#         for key, idx_lis in grp_idx.items():\n",
    "#             df_dict[key] = wide_format_test(features.loc[idx_lis])\n",
    "#         return df_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = mod_dict #{i: pickle.load(open('../model/ridge{}.sav'.format(i), 'rb')) for i in range(2)}\n",
    "\n",
    "def get_r_hat(A, B): \n",
    "    \"\"\"\n",
    "        A: 1440-by-10 dataframe of log prices with columns log_pr_0, ... , log_pr_9\n",
    "        B: 1440-by-10 dataframe of trading volumes with columns volu_0, ... , volu_9    \n",
    "        return: a numpy array of length 10, corresponding to the predictions for the forward 30-minutes returns of assets 0, 1, 2, ..., 9\n",
    "    \"\"\"\n",
    "    grp_idx = {i: [i] for i in range(10)}\n",
    "    x = get_feature_test(A, B, grp_idx=grp_idx)\n",
    "    pred_dict = {i: model.predict(x[i]) for i, model in model_dict.items()}\n",
    "    \n",
    "    out = np.zeros(10)\n",
    "    for keys, idx in grp_idx.items():\n",
    "        out[idx] = pred_dict.get(keys)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tune(log_pr_test, volu_test):\n",
    "\n",
    "    t0 = time.time()\n",
    "    dt = datetime.timedelta(days=1)\n",
    "\n",
    "    r_fwd = (log_pr_test.shift(-30) - log_pr_test).iloc[1440::10]\n",
    "    # r_fwd = return_true.iloc[1440::10]\n",
    "    # r_fwd.index = log_pr_test.index[1440::10]\n",
    "    r_hat = pd.DataFrame(index=log_pr_test.index[1440::10], columns=log_pr_test.columns, dtype=np.float64)\n",
    "\n",
    "    for t in log_pr_test.index[1440::10]: # compute the predictions every 10 minutes\n",
    "        # inputs 1 day of log price and volume\n",
    "        r_hat.loc[t, :] = get_r_hat(log_pr_test.loc[(t - dt):t], volu_test.loc[(t - dt):t])\n",
    "    t_used = time.time() - t0\n",
    "    print(\"Time used: \", t_used)\n",
    "\n",
    "    r_fwd_all = r_fwd.iloc[:-3].values.ravel() # the final 3 rows are NaNs. \n",
    "    r_hat_all = r_hat.iloc[:-3].values.ravel()\n",
    "    return r_fwd.corrwith(r_hat), np.corrcoef(r_fwd_all, r_hat_all)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pr_test = log_pr[:train_split_t]\n",
    "volu_test = volu[:train_split_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,6) and (10,) not aligned: 6 (dim 1) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\royul\\Documents\\GitHub\\multivariate-time-series-prediction\\models(ipynb)\\OLS.ipynb Cell 29'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/royul/Documents/GitHub/multivariate-time-series-prediction/models%28ipynb%29/OLS.ipynb#ch0000036?line=0'>1</a>\u001b[0m evaluate_tune(log_pr_test, volu_test)\n",
      "\u001b[1;32mc:\\Users\\royul\\Documents\\GitHub\\multivariate-time-series-prediction\\models(ipynb)\\OLS.ipynb Cell 27'\u001b[0m in \u001b[0;36mevaluate_tune\u001b[1;34m(log_pr_test, volu_test)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/royul/Documents/GitHub/multivariate-time-series-prediction/models%28ipynb%29/OLS.ipynb#ch0000032?line=8'>9</a>\u001b[0m r_hat \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(index\u001b[39m=\u001b[39mlog_pr_test\u001b[39m.\u001b[39mindex[\u001b[39m1440\u001b[39m::\u001b[39m10\u001b[39m], columns\u001b[39m=\u001b[39mlog_pr_test\u001b[39m.\u001b[39mcolumns, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/royul/Documents/GitHub/multivariate-time-series-prediction/models%28ipynb%29/OLS.ipynb#ch0000032?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m log_pr_test\u001b[39m.\u001b[39mindex[\u001b[39m1440\u001b[39m::\u001b[39m10\u001b[39m]: \u001b[39m# compute the predictions every 10 minutes\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/royul/Documents/GitHub/multivariate-time-series-prediction/models%28ipynb%29/OLS.ipynb#ch0000032?line=11'>12</a>\u001b[0m     \u001b[39m# inputs 1 day of log price and volume\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/royul/Documents/GitHub/multivariate-time-series-prediction/models%28ipynb%29/OLS.ipynb#ch0000032?line=12'>13</a>\u001b[0m     r_hat\u001b[39m.\u001b[39mloc[t, :] \u001b[39m=\u001b[39m get_r_hat(log_pr_test\u001b[39m.\u001b[39;49mloc[(t \u001b[39m-\u001b[39;49m dt):t], volu_test\u001b[39m.\u001b[39;49mloc[(t \u001b[39m-\u001b[39;49m dt):t])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/royul/Documents/GitHub/multivariate-time-series-prediction/models%28ipynb%29/OLS.ipynb#ch0000032?line=13'>14</a>\u001b[0m t_used \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t0\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/royul/Documents/GitHub/multivariate-time-series-prediction/models%28ipynb%29/OLS.ipynb#ch0000032?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTime used: \u001b[39m\u001b[39m\"\u001b[39m, t_used)\n",
      "\u001b[1;32mc:\\Users\\royul\\Documents\\GitHub\\multivariate-time-series-prediction\\models(ipynb)\\OLS.ipynb Cell 25'\u001b[0m in \u001b[0;36mget_r_hat\u001b[1;34m(A, B)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/royul/Documents/GitHub/multivariate-time-series-prediction/models%28ipynb%29/OLS.ipynb#ch0000030?line=8'>9</a>\u001b[0m grp_idx \u001b[39m=\u001b[39m {i: [i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m)}\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/royul/Documents/GitHub/multivariate-time-series-prediction/models%28ipynb%29/OLS.ipynb#ch0000030?line=9'>10</a>\u001b[0m x \u001b[39m=\u001b[39m get_feature_test(A, B, grp_idx\u001b[39m=\u001b[39mgrp_idx)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/royul/Documents/GitHub/multivariate-time-series-prediction/models%28ipynb%29/OLS.ipynb#ch0000030?line=10'>11</a>\u001b[0m pred_dict \u001b[39m=\u001b[39m {i: model\u001b[39m.\u001b[39mpredict(x[i]) \u001b[39mfor\u001b[39;00m i, model \u001b[39min\u001b[39;00m model_dict\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/royul/Documents/GitHub/multivariate-time-series-prediction/models%28ipynb%29/OLS.ipynb#ch0000030?line=12'>13</a>\u001b[0m out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39m10\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/royul/Documents/GitHub/multivariate-time-series-prediction/models%28ipynb%29/OLS.ipynb#ch0000030?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m keys, idx \u001b[39min\u001b[39;00m grp_idx\u001b[39m.\u001b[39mitems():\n",
      "\u001b[1;32mc:\\Users\\royul\\Documents\\GitHub\\multivariate-time-series-prediction\\models(ipynb)\\OLS.ipynb Cell 25'\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/royul/Documents/GitHub/multivariate-time-series-prediction/models%28ipynb%29/OLS.ipynb#ch0000030?line=8'>9</a>\u001b[0m grp_idx \u001b[39m=\u001b[39m {i: [i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m)}\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/royul/Documents/GitHub/multivariate-time-series-prediction/models%28ipynb%29/OLS.ipynb#ch0000030?line=9'>10</a>\u001b[0m x \u001b[39m=\u001b[39m get_feature_test(A, B, grp_idx\u001b[39m=\u001b[39mgrp_idx)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/royul/Documents/GitHub/multivariate-time-series-prediction/models%28ipynb%29/OLS.ipynb#ch0000030?line=10'>11</a>\u001b[0m pred_dict \u001b[39m=\u001b[39m {i: model\u001b[39m.\u001b[39;49mpredict(x[i]) \u001b[39mfor\u001b[39;00m i, model \u001b[39min\u001b[39;00m model_dict\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/royul/Documents/GitHub/multivariate-time-series-prediction/models%28ipynb%29/OLS.ipynb#ch0000030?line=12'>13</a>\u001b[0m out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39m10\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/royul/Documents/GitHub/multivariate-time-series-prediction/models%28ipynb%29/OLS.ipynb#ch0000030?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m keys, idx \u001b[39min\u001b[39;00m grp_idx\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1159\u001b[0m, in \u001b[0;36mResults.predict\u001b[1;34m(self, exog, transform, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/royul/miniconda3/lib/site-packages/statsmodels/base/model.py?line=1155'>1156</a>\u001b[0m         exog \u001b[39m=\u001b[39m exog[:, \u001b[39mNone\u001b[39;00m]\n\u001b[0;32m   <a href='file:///c%3A/Users/royul/miniconda3/lib/site-packages/statsmodels/base/model.py?line=1156'>1157</a>\u001b[0m     exog \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39matleast_2d(exog)  \u001b[39m# needed in count model shape[1]\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/royul/miniconda3/lib/site-packages/statsmodels/base/model.py?line=1158'>1159</a>\u001b[0m predict_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams, exog, \u001b[39m*\u001b[39;49margs,\n\u001b[0;32m   <a href='file:///c%3A/Users/royul/miniconda3/lib/site-packages/statsmodels/base/model.py?line=1159'>1160</a>\u001b[0m                                      \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/royul/miniconda3/lib/site-packages/statsmodels/base/model.py?line=1161'>1162</a>\u001b[0m \u001b[39mif\u001b[39;00m exog_index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(predict_results,\n\u001b[0;32m   <a href='file:///c%3A/Users/royul/miniconda3/lib/site-packages/statsmodels/base/model.py?line=1162'>1163</a>\u001b[0m                                           \u001b[39m'\u001b[39m\u001b[39mpredicted_values\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/royul/miniconda3/lib/site-packages/statsmodels/base/model.py?line=1163'>1164</a>\u001b[0m     \u001b[39mif\u001b[39;00m predict_results\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:381\u001b[0m, in \u001b[0;36mRegressionModel.predict\u001b[1;34m(self, params, exog)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/royul/miniconda3/lib/site-packages/statsmodels/regression/linear_model.py?line=377'>378</a>\u001b[0m \u001b[39mif\u001b[39;00m exog \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/royul/miniconda3/lib/site-packages/statsmodels/regression/linear_model.py?line=378'>379</a>\u001b[0m     exog \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog\n\u001b[1;32m--> <a href='file:///c%3A/Users/royul/miniconda3/lib/site-packages/statsmodels/regression/linear_model.py?line=380'>381</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mdot(exog, params)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1,6) and (10,) not aligned: 6 (dim 1) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "evaluate_tune(log_pr_test, volu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pr_test = log_pr\n",
    "volu_test = volu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_tune(log_pr_test, volu_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bcbeb1c3c4ccee2109855bb42e1bb012102ee5721b972abedda41e225a004887"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
