{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model with AIC feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear method makes use of the log backward return (log price difference) to predict foward return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training:\n",
    "1) Ridge regression: on 30 features\n",
    "2) PC regression: pca on 30 features then perform ols\n",
    "\n",
    "Feature: 10 stocks, each with 3 backward return (say, 3min, 7min, 10min, see correlation to decide)\n",
    "\n",
    "Response: 10 stocks' 30min forward return. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "log_pr = pd.read_pickle(\"../data/log_price.df\")\n",
    "volu = pd.read_pickle(\"../data/volume_usd.df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "def logr(dta,min):\n",
    "    '''\n",
    "    Input\n",
    "    dta: pandas dataframe nxp\n",
    "    min: backward length\n",
    "    Return\n",
    "    log return: pandas dataframe\n",
    "    '''\n",
    "    return dta.diff(min,0).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_begin_idx = log_pr.index[30]\n",
    "x_end_idx = log_pr.index[-31]\n",
    "y_begin_idx = log_pr.index[60]\n",
    "\n",
    "x = pd.concat((logr(log_pr,3)[x_begin_idx:x_end_idx],\n",
    "                logr(log_pr,5)[x_begin_idx:x_end_idx],\n",
    "                logr(log_pr,7)[x_begin_idx:x_end_idx]),axis=1)\n",
    "y = log_pr.diff(30)[y_begin_idx:]\n",
    "y = y.set_index(x.index)\n",
    "\n",
    "xtrain,xvali,xtest = x[:log_pr.index[-87841]],x[log_pr.index[-87840]:log_pr.index[-44641]],x[log_pr.index[-44640]:]\n",
    "ytrain,yvali,ytest= y[:log_pr.index[-87841]],y[log_pr.index[-87840]:log_pr.index[-44641]],y[log_pr.index[-44640]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.032893\n",
      "1    0.080887\n",
      "2   -0.000749\n",
      "3    0.032757\n",
      "4    0.022005\n",
      "5    0.001495\n",
      "6    0.039881\n",
      "7    0.004303\n",
      "8    0.031240\n",
      "9    0.031535\n",
      "dtype: float64\n",
      "-0.7025580922020436\n"
     ]
    }
   ],
   "source": [
    "# Model Fitting\n",
    "from sklearn.linear_model import Ridge\n",
    "rr = Ridge(alpha=0.5).fit(xtrain,ytrain)\n",
    "# 10-minute-rolling 30-min log-return prediction for validation set\n",
    "yvali_hat_ridge = pd.DataFrame(rr.predict(xvali),columns={i for i in range(10)},index=yvali.index)[::10]\n",
    "# compute pairwise correlation\n",
    "print(yvali_hat_ridge.corrwith(yvali[::10]))\n",
    "print(np.corrcoef(yvali_hat_ridge,yvali[::10])[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem:\n",
    "\n",
    "Too many observations makes it impossible to use kernel methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "# Gaussian Kernel\n",
    "kr = KernelRidge(alpha=1,kernel='rbf',gamma=1).fit(xtrain,ytrain)\n",
    "# 10-minute-rolling 30-min log-return prediction for validation set\n",
    "yvali_hat_ridge = pd.DataFrame(kr.predict(xvali),columns={i for i in range(10)},index=yvali.index)[::10]\n",
    "# compute pairwise correlation\n",
    "yvali_hat_ridge.corrwith(yvali[::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used:  16.31000018119812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02322928304075363"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_r_hat(A, B): \n",
    "    x = pd.concat((A.diff(3,0).iloc[-1],A.diff(5,0).iloc[-1],A.diff(7,0).iloc[-1]))\n",
    "    x = pd.DataFrame(x).transpose()\n",
    "    return rr.predict(x)\n",
    "\n",
    "def evaluate(log_pr_test, volu_test):\n",
    "    t0 = time.time()\n",
    "    dt = datetime.timedelta(days=1)\n",
    "\n",
    "    r_fwd = (log_pr_test.shift(-30) - log_pr_test).iloc[1440::10]\n",
    "    r_hat = pd.DataFrame(index=log_pr_test.index[1440::10], columns=np.arange(10), dtype=np.float64)\n",
    "\n",
    "    for t in log_pr_test.index[1440::10]: # compute the predictions every 10 minutes\n",
    "        # inputs 1 day of log price and volume\n",
    "        r_hat.loc[t, :] = get_r_hat(log_pr_test.loc[(t - dt):t], volu_test.loc[(t - dt):t])\n",
    "    t_used = time.time() - t0\n",
    "    print(\"Time used: \", t_used)\n",
    "\n",
    "    r_fwd_all = r_fwd.iloc[:-3].values.ravel() # the final 3 rows are NaNs. \n",
    "    r_hat_all = r_hat.iloc[:-3].values.ravel()\n",
    "    return np.corrcoef(r_fwd_all, r_hat_all)[0,1]\n",
    "\n",
    "evaluate(log_pr[log_pr.index[-44640]:],volu[log_pr.index[-44640]:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.011665\n",
       "1    0.054788\n",
       "2   -0.002117\n",
       "3    0.000857\n",
       "4    0.010895\n",
       "5    0.022066\n",
       "6    0.031792\n",
       "7    0.005105\n",
       "8    0.059085\n",
       "9    0.038133\n",
       "dtype: float64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA transformation\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "pca = PCA()\n",
    "xtrain_pc = pca.fit_transform(scale(xtrain))[:,:20]\n",
    "# Model Training\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression().fit(xtrain_pc,ytrain)\n",
    "# Evaluation on Validation data\n",
    "xvali_pc = pca.transform(scale(xvali))[:,:20]\n",
    "yvali_hat_pca = pd.DataFrame(lr.predict(xvali_pc),columns={i for i in range(10)},index=yvali.index)\n",
    "yvali_hat_pca.corrwith(yvali)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel pca regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used:  14.433970928192139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015289318934865622"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_r_hat(A, B): \n",
    "    x = pd.concat((A.diff(3,0).iloc[-1],A.diff(5,0).iloc[-1],A.diff(7,0).iloc[-1]))\n",
    "    x = pd.DataFrame(x).transpose()\n",
    "    x_pc = pca.transform(x)\n",
    "    return rr.predict(x_pc)\n",
    "\n",
    "def evaluate(log_pr_test, volu_test):\n",
    "    t0 = time.time()\n",
    "    dt = datetime.timedelta(days=1)\n",
    "\n",
    "    r_fwd = (log_pr_test.shift(-30) - log_pr_test).iloc[1440::10]\n",
    "    r_hat = pd.DataFrame(index=log_pr_test.index[1440::10], columns=np.arange(10), dtype=np.float64)\n",
    "\n",
    "    for t in log_pr_test.index[1440::10]: # compute the predictions every 10 minutes\n",
    "        # inputs 1 day of log price and volume\n",
    "        r_hat.loc[t, :] = get_r_hat(log_pr_test.loc[(t - dt):t], volu_test.loc[(t - dt):t])\n",
    "    t_used = time.time() - t0\n",
    "    print(\"Time used: \", t_used)\n",
    "\n",
    "    r_fwd_all = r_fwd.iloc[:-3].values.ravel() # the final 3 rows are NaNs. \n",
    "    r_hat_all = r_hat.iloc[:-3].values.ravel()\n",
    "    return np.corrcoef(r_fwd_all, r_hat_all)[0,1]\n",
    "\n",
    "evaluate(log_pr[log_pr.index[-44640]:],volu[log_pr.index[-44640]:])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bcbeb1c3c4ccee2109855bb42e1bb012102ee5721b972abedda41e225a004887"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
