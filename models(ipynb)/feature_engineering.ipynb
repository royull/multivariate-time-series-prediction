{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "log_pr = pd.read_pickle(\"../data/log_price.df\")\n",
    "volu = pd.read_pickle(\"../data/volume_usd.df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = log_pr.reset_index().melt(id_vars=['timestamp'])\n",
    "features.columns = ['timestamp', 'stock', 'log_pr']\n",
    "features = features.set_index(['timestamp', 'stock']).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backward returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [3, 5, 10, 20]:\n",
    "    features['log_pr_{}'.format(i)] = -features.groupby(level='stock').log_pr.diff(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-07-01 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01 00:01:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01 00:02:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01 00:03:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01 00:04:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01 00:05:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01 00:06:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01 00:07:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01 00:08:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01 00:09:00</th>\n",
       "      <td>-0.000918</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>-0.000431</td>\n",
       "      <td>-0.003427</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>-0.003746</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>-0.00004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1         2         3         4  \\\n",
       "timestamp                                                               \n",
       "2021-07-01 00:00:00       NaN       NaN       NaN       NaN       NaN   \n",
       "2021-07-01 00:01:00       NaN       NaN       NaN       NaN       NaN   \n",
       "2021-07-01 00:02:00       NaN       NaN       NaN       NaN       NaN   \n",
       "2021-07-01 00:03:00       NaN       NaN       NaN       NaN       NaN   \n",
       "2021-07-01 00:04:00       NaN       NaN       NaN       NaN       NaN   \n",
       "2021-07-01 00:05:00       NaN       NaN       NaN       NaN       NaN   \n",
       "2021-07-01 00:06:00       NaN       NaN       NaN       NaN       NaN   \n",
       "2021-07-01 00:07:00       NaN       NaN       NaN       NaN       NaN   \n",
       "2021-07-01 00:08:00       NaN       NaN       NaN       NaN       NaN   \n",
       "2021-07-01 00:09:00 -0.000918  0.000536  0.001157 -0.000431 -0.003427   \n",
       "\n",
       "                            5         6         7         8        9  \n",
       "timestamp                                                             \n",
       "2021-07-01 00:00:00       NaN       NaN       NaN       NaN      NaN  \n",
       "2021-07-01 00:01:00       NaN       NaN       NaN       NaN      NaN  \n",
       "2021-07-01 00:02:00       NaN       NaN       NaN       NaN      NaN  \n",
       "2021-07-01 00:03:00       NaN       NaN       NaN       NaN      NaN  \n",
       "2021-07-01 00:04:00       NaN       NaN       NaN       NaN      NaN  \n",
       "2021-07-01 00:05:00       NaN       NaN       NaN       NaN      NaN  \n",
       "2021-07-01 00:06:00       NaN       NaN       NaN       NaN      NaN  \n",
       "2021-07-01 00:07:00       NaN       NaN       NaN       NaN      NaN  \n",
       "2021-07-01 00:08:00       NaN       NaN       NaN       NaN      NaN  \n",
       "2021-07-01 00:09:00  0.000505 -0.003746  0.000405  0.002177 -0.00004  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = log_pr.rolling(10).mean()\n",
    "temp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log volume and volume backward diffrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>volu</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th>stock</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">2021-07-01</th>\n",
       "      <th>0</th>\n",
       "      <td>1.475069e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.808116e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.860058e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.601353e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.765960e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.916289e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.544255e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.801509e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.151507e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.568141e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          volu\n",
       "timestamp  stock              \n",
       "2021-07-01 0      1.475069e+05\n",
       "           1      5.808116e+05\n",
       "           2      1.860058e+04\n",
       "           3      1.601353e+05\n",
       "           4      2.765960e+05\n",
       "           5      2.916289e+05\n",
       "           6      8.544255e+05\n",
       "           7      1.801509e+05\n",
       "           8      4.151507e+06\n",
       "           9      7.568141e+06"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volu_df = volu.reset_index().melt(id_vars=['timestamp'])\n",
    "volu_df.columns = ['timestamp', 'stock', 'volu']\n",
    "volu_df = volu_df.set_index(['timestamp', 'stock']).sort_index()\n",
    "volu_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fn = lambda x: np.log(x+1)\n",
    "features['log_volu'] = volu_df.groupby(level='stock').volu.apply(log_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1]:\n",
    "    features['log_volu_{}'.format(i)] = features.groupby(level='stock').log_volu.diff(i)\n",
    "    # features['volu_{}',format(i)] = volu_df.groupby(level='stock').volu.diff(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Moving average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [10, 30, 50]:\n",
    "    ema = lambda x: x.ewm(span=i).mean()\n",
    "    features['pr_ema_{}'.format(i)] = features.groupby(level='stock').log_pr.apply(ema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsi(close_delta, periods=20, ema=True):\n",
    "    \"\"\"\n",
    "    Returns a pd.Series with the relative strength index.\n",
    "    \"\"\"\n",
    "    close_delta = close_delta.diff()\n",
    "\n",
    "    # Make two series: one for lower closes and one for higher closes\n",
    "    up = close_delta.clip(lower=0)\n",
    "    down = -1 * close_delta.clip(upper=0)\n",
    "    \n",
    "    if ema == True:\n",
    "\t    # Use exponential moving average\n",
    "        ma_up = up.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n",
    "        ma_down = down.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n",
    "    else:\n",
    "        # Use simple moving average\n",
    "        ma_up = up.rolling(window = periods, adjust=False).mean()\n",
    "        ma_down = down.rolling(window = periods, adjust=False).mean()\n",
    "        \n",
    "    rsi = ma_up / ma_down\n",
    "    rsi = 100 - (100/(1 + rsi))\n",
    "    return rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['rsi_20'] = features.groupby(level='stock').log_pr.apply(rsi)\n",
    "features['rsi_30'] = features.groupby(level='stock').log_pr.apply(rsi, periods=30)\n",
    "features['rsi_50'] = features.groupby(level='stock').log_pr.apply(rsi, periods=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving std. and Range of Oscillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std_5 = lambda x: x.rolling(5).std()\n",
    "std_10 = lambda x: x.rolling(10).std()\n",
    "features['pr_3_std_10'] = features.groupby(level='stock').log_pr_3.apply(std_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adr(log_pr, window=10, min_periods=10):\n",
    "    high = log_pr.rolling(window=window, min_periods=min_periods).max()\n",
    "    low = log_pr.rolling(window=window, min_periods=min_periods).min()\n",
    "\n",
    "    # average over window\n",
    "    ma_high = high.rolling(window=window).mean()\n",
    "    ma_low = low.rolling(window=window).mean()\n",
    "\n",
    "    ratio = ma_high/ma_low\n",
    "\n",
    "    return 100 * (ratio - 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['pr_adr_20'] = features.groupby(level='stock').log_pr.apply(adr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### z score of volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roll_rank_fn = lambda x: x.rolling(240, min_period=20).apply(lambda x: pd.Series(x).rank(pct=True)[0])\n",
    "zscore_fn = lambda x: (x - x.rolling(window=240, min_periods=20).mean()) / x.rolling(window=240, min_periods=20).std()\n",
    "features['volu_z_score'] = volu_df.groupby(level='stock').volu.apply(zscore_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stock  timestamp            stock\n",
       "0      2021-07-01 00:00:00  0                 NaN\n",
       "       2021-07-01 00:01:00  0                 NaN\n",
       "       2021-07-01 00:02:00  0                 NaN\n",
       "       2021-07-01 00:03:00  0                 NaN\n",
       "       2021-07-01 00:04:00  0                 NaN\n",
       "                                         ...     \n",
       "9      2021-12-31 23:55:00  9        6.669354e+07\n",
       "       2021-12-31 23:56:00  9        6.669354e+07\n",
       "       2021-12-31 23:57:00  9        6.669354e+07\n",
       "       2021-12-31 23:58:00  9        6.669354e+07\n",
       "       2021-12-31 23:59:00  9        6.669354e+07\n",
       "Name: volu, Length: 2649600, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volu_df.groupby(level='stock').volu.rolling(200, min_periods=20).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform back to wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = features.reset_index(level=['stock']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = feature_df.pivot(columns ='stock')\n",
    "temp.columns = temp.columns.get_level_values(0) + '_' +  [str(x) for x in temp.columns.get_level_values(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.iloc[30:].isnull().any().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(dta):\n",
    "    # Compute the mean and interquartile range\n",
    "    mean = dta.mean(0)\n",
    "    iqr = dta.quantile([0.25, 0.75], axis=0).diff().T.iloc[:, 1]\n",
    "    \n",
    "    # Replace entries that are more than 10 times the IQR\n",
    "    # away from the mean with NaN (denotes a missing entry)\n",
    "    mask = np.abs(dta) > mean + 10 * iqr\n",
    "    treated = dta.copy()\n",
    "    treated[mask] = np.nan\n",
    "\n",
    "    return treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_format(df):\n",
    "    df_= df.reset_index(level=['stock']).sort_index()\n",
    "    df_ = df_.pivot(columns ='stock')\n",
    "    df_.columns = df_.columns.get_level_values(0) + '_' +  [str(x) for x in df_.columns.get_level_values(1)]\n",
    "\n",
    "    return df_\n",
    "\n",
    "\n",
    "def get_feature_train(log_pr, volu, x_begin_idx, x_end_idx, y_begin_idx, \n",
    "                        grp_idx=None, rm_outlier=False, print_cor=True):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    log_pr (pdSeries): train set\n",
    "    volu (pdSeries): train set\n",
    "    x_begin_idx (pdIndex): to truncate the NaNs\n",
    "    grp_idx (dict): key is group idx, value is list of stock idx\n",
    "\n",
    "    Returns:\n",
    "    feature_dict (dict): key is group idx, value is a tuple of feature matrix and response\n",
    "    \"\"\"\n",
    "\n",
    "    log_pr_df = log_pr.reset_index().melt(id_vars=['timestamp'])\n",
    "    log_pr_df.columns = ['timestamp', 'stock', 'log_pr']\n",
    "    log_pr_df = log_pr_df.set_index(['timestamp', 'stock']).sort_index()\n",
    "\n",
    "    volu_df = volu.reset_index().melt(id_vars=['timestamp'])\n",
    "    volu_df.columns = ['timestamp', 'stock', 'volu']\n",
    "    volu_df = volu_df.set_index(['timestamp', 'stock']).sort_index()\n",
    "\n",
    "    features = pd.DataFrame(index=log_pr_df.index)\n",
    "\n",
    "    # log_pr feature\n",
    "    for i in [3, 10, 20, 30]:\n",
    "        features['log_pr_{}'.format(i)] = -log_pr_df.groupby(level='stock').log_pr.diff(i)\n",
    "\n",
    "    # # EMA\n",
    "    # ema = lambda x: x.ewm(span=i).mean()\n",
    "    # for i in [10, 30, 50]:\n",
    "    #     features['pr_ema_{}'.format(i)] = log_pr_df.groupby(level='stock').log_pr.apply(ema)\n",
    "\n",
    "    # MA\n",
    "    for i in [10, 30, 50]:\n",
    "        features['pr_ema_{}'.format(i)] = log_pr_df.groupby(level='stock').rolling(i).mean()\n",
    "\n",
    "    std_10 = lambda x: x.rolling(10).std()\n",
    "    features['log_pr_std_10'] = log_pr_df.groupby(level='stock').log_pr.apply(std_10)\n",
    "\n",
    "    # RSI\n",
    "    features['rsi_20'] = log_pr_df.groupby(level='stock').log_pr.apply(rsi)\n",
    "    features['rsi_30'] = log_pr_df.groupby(level='stock').log_pr.apply(rsi, periods=30)\n",
    "    # features['rsi_50'] = log_pr_df.groupby(level='stock').log_pr.apply(rsi, periods=50)\n",
    "    \n",
    "    # # ADR\n",
    "    # features['pr_adr_20'] = log_pr_df.groupby(level='stock').log_pr.apply(adr)\n",
    "\n",
    "    # volume feature\n",
    "    log_fn = lambda x: np.log(x+1)\n",
    "    features['log_volu'] = volu_df.groupby(level='stock').volu.apply(log_fn)\n",
    "\n",
    "    # stdised volume in 2 hours backward rolling windows\n",
    "    zscore_fn = lambda x: (x - x.rolling(window=240, min_periods=20).mean()) / x.rolling(window=240, min_periods=20).std()\n",
    "    features['volu_z_score'] = volu_df.groupby(level='stock').volu.apply(zscore_fn)\n",
    "\n",
    "    # feature_dropped = features.iloc[x_begin_idx:x_end_idx]\n",
    "    response = log_pr.diff(30)\n",
    "    # print(features.shape)\n",
    "    # print(feature_dropped.shape)\n",
    "    # print(response_dropped.shape)\n",
    "\n",
    "    if grp_idx is not None:\n",
    "        feature_dict = {}\n",
    "        for key, idx_lis in grp_idx.items():\n",
    "            feature_df_dropped = wide_format(features.loc[pd.IndexSlice[:,idx_lis],:])\n",
    "            # transform back to wide format\n",
    "            feature_dict[key] = (feature_df_dropped.iloc[x_begin_idx:x_end_idx], \n",
    "                                            response[idx_lis].iloc[y_begin_idx:])\n",
    "        return feature_dict\n",
    "    else:\n",
    "        # transform back to wide format\n",
    "        feature_df_dropped = wide_format(features).iloc[x_begin_idx:x_end_idx]\n",
    "        # feature_df_dropped = feature_df[x_begin_idx:x_end_idx]\n",
    "    \n",
    "        if print_cor:\n",
    "            for i in range(10):\n",
    "                feature_train_0 = features.xs(i, level='stock')\n",
    "                print(feature_train_0.corrwith(response[i]))\n",
    "\n",
    "        return feature_df_dropped, response.iloc[y_begin_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_format_test(df):\n",
    "    df_= df.reset_index()\n",
    "    df_ = df_.pivot(columns ='index').apply(lambda s: s.dropna().reset_index(drop=True))\n",
    "    df_.columns = df_.columns.get_level_values(0) + '_' +  [str(x) for x in df_.columns.get_level_values(1)]\n",
    "\n",
    "    return df_\n",
    "\n",
    "def get_feature_test(log_pr, volu, grp_idx=None):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    log_pr (pdSeries): 1 day of log pr \n",
    "    volu (pdSeries): 1 day of volume\n",
    "\n",
    "    Output:\n",
    "    test data frame\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame(index=log_pr.columns)\n",
    "\n",
    "    # backward return\n",
    "    # print(-(log_pr.iloc[-1] - log_pr.iloc[-30]).values)\n",
    "    for i in [10, 20, 30]:\n",
    "        features['log_pr_{}'.format(i)] = -(log_pr.iloc[-1] - log_pr.iloc[-i]).values\n",
    "    # backward rolling std\n",
    "    features['log_pr_std_10'] = log_pr.iloc[-10:].std(0).values\n",
    "    \n",
    "    # volume features\n",
    "    features['log_volu'] = np.log(volu.iloc[-1].values + 1)\n",
    "    features['volu_z_score'] = ((volu.iloc[-1] - volu.iloc[-240:].mean())/volu.iloc[-240:].std()).values\n",
    "\n",
    "    if grp_idx is None:\n",
    "        return wide_format_test(features)\n",
    "    else:\n",
    "        df_dict = {}\n",
    "        for key, idx_lis in grp_idx.items():\n",
    "            df_dict[key] = wide_format_test(features.loc[idx_lis])\n",
    "        return df_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "       # if rm_outlier:\n",
    "        #     feature_df_dropped = remove_outliers(feature_df)\n",
    "        #     na_idx = feature_df_dropped.isnull().any(1)\n",
    "        #     response_dropped[na_idx] = np.nan\n",
    "\n",
    "        #     return feature_df_dropped.dropna(), response_dropped.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_pr_3        -0.309250\n",
      "log_pr_10       -0.566440\n",
      "log_pr_20       -0.807458\n",
      "log_pr_30       -1.000000\n",
      "pr_ema_10        0.002535\n",
      "pr_ema_30       -0.006325\n",
      "pr_ema_50       -0.011227\n",
      "log_pr_std_10    0.294352\n",
      "rsi_20           0.754775\n",
      "rsi_30           0.772893\n",
      "rsi_50           0.738094\n",
      "pr_adr_20       -0.001367\n",
      "log_volu         0.137962\n",
      "volu_z_score     0.157233\n",
      "dtype: float64\n",
      "log_pr_3        -0.303509\n",
      "log_pr_10       -0.564339\n",
      "log_pr_20       -0.810175\n",
      "log_pr_30       -1.000000\n",
      "pr_ema_10        0.000539\n",
      "pr_ema_30       -0.006753\n",
      "pr_ema_50       -0.010747\n",
      "log_pr_std_10    0.353098\n",
      "rsi_20           0.657330\n",
      "rsi_30           0.680200\n",
      "rsi_50           0.661198\n",
      "pr_adr_20       -0.002536\n",
      "log_volu         0.138490\n",
      "volu_z_score     0.188771\n",
      "dtype: float64\n",
      "log_pr_3        -0.306207\n",
      "log_pr_10       -0.566170\n",
      "log_pr_20       -0.811186\n",
      "log_pr_30       -1.000000\n",
      "pr_ema_10        0.000290\n",
      "pr_ema_30       -0.004223\n",
      "pr_ema_50       -0.006759\n",
      "log_pr_std_10    0.308044\n",
      "rsi_20           0.730604\n",
      "rsi_30           0.747616\n",
      "rsi_50           0.712901\n",
      "pr_adr_20        0.000522\n",
      "log_volu         0.087845\n",
      "volu_z_score     0.168640\n",
      "dtype: float64\n",
      "log_pr_3        -0.304225\n",
      "log_pr_10       -0.557927\n",
      "log_pr_20       -0.798424\n",
      "log_pr_30       -1.000000\n",
      "pr_ema_10        0.018794\n",
      "pr_ema_30        0.008182\n",
      "pr_ema_50        0.002313\n",
      "log_pr_std_10    0.320963\n",
      "rsi_20           0.762987\n",
      "rsi_30           0.781286\n",
      "rsi_50           0.745456\n",
      "pr_adr_20        0.001586\n",
      "log_volu         0.143790\n",
      "volu_z_score     0.148591\n",
      "dtype: float64\n",
      "log_pr_3        -0.291789\n",
      "log_pr_10       -0.540513\n",
      "log_pr_20       -0.782071\n",
      "log_pr_30       -1.000000\n",
      "pr_ema_10        0.006576\n",
      "pr_ema_30       -0.001732\n",
      "pr_ema_50       -0.006170\n",
      "log_pr_std_10    0.173689\n",
      "rsi_20           0.735716\n",
      "rsi_30           0.751524\n",
      "rsi_50           0.716726\n",
      "pr_adr_20       -0.002803\n",
      "log_volu         0.084277\n",
      "volu_z_score     0.092012\n",
      "dtype: float64\n",
      "log_pr_3        -0.307938\n",
      "log_pr_10       -0.569446\n",
      "log_pr_20       -0.805383\n",
      "log_pr_30       -1.000000\n",
      "pr_ema_10        0.022340\n",
      "pr_ema_30        0.012752\n",
      "pr_ema_50        0.007357\n",
      "log_pr_std_10    0.251723\n",
      "rsi_20           0.739560\n",
      "rsi_30           0.758920\n",
      "rsi_50           0.727283\n",
      "pr_adr_20       -0.001572\n",
      "log_volu         0.137177\n",
      "volu_z_score     0.159583\n",
      "dtype: float64\n",
      "log_pr_3        -0.301706\n",
      "log_pr_10       -0.559884\n",
      "log_pr_20       -0.800046\n",
      "log_pr_30       -1.000000\n",
      "pr_ema_10        0.021814\n",
      "pr_ema_30        0.007098\n",
      "pr_ema_50       -0.000879\n",
      "log_pr_std_10    0.334323\n",
      "rsi_20           0.703209\n",
      "rsi_30           0.726566\n",
      "rsi_50           0.703914\n",
      "pr_adr_20       -0.005309\n",
      "log_volu         0.115137\n",
      "volu_z_score     0.148388\n",
      "dtype: float64\n",
      "log_pr_3        -0.306226\n",
      "log_pr_10       -0.554904\n",
      "log_pr_20       -0.791840\n",
      "log_pr_30       -1.000000\n",
      "pr_ema_10        0.010416\n",
      "pr_ema_30        0.002030\n",
      "pr_ema_50       -0.002703\n",
      "log_pr_std_10    0.240905\n",
      "rsi_20           0.798036\n",
      "rsi_30           0.814130\n",
      "rsi_50           0.773391\n",
      "pr_adr_20       -0.003974\n",
      "log_volu         0.138887\n",
      "volu_z_score     0.145879\n",
      "dtype: float64\n",
      "log_pr_3        -0.295703\n",
      "log_pr_10       -0.554131\n",
      "log_pr_20       -0.799655\n",
      "log_pr_30       -1.000000\n",
      "pr_ema_10        0.025076\n",
      "pr_ema_30        0.009889\n",
      "pr_ema_50        0.001704\n",
      "log_pr_std_10    0.173615\n",
      "rsi_20           0.782003\n",
      "rsi_30           0.792116\n",
      "rsi_50           0.745794\n",
      "pr_adr_20        0.004018\n",
      "log_volu         0.127240\n",
      "volu_z_score     0.127015\n",
      "dtype: float64\n",
      "log_pr_3        -0.306885\n",
      "log_pr_10       -0.570810\n",
      "log_pr_20       -0.813818\n",
      "log_pr_30       -1.000000\n",
      "pr_ema_10        0.008187\n",
      "pr_ema_30        0.001344\n",
      "pr_ema_50       -0.002472\n",
      "log_pr_std_10    0.112637\n",
      "rsi_20           0.762049\n",
      "rsi_30           0.771250\n",
      "rsi_50           0.724175\n",
      "pr_adr_20        0.001117\n",
      "log_volu         0.135982\n",
      "volu_z_score     0.137459\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_train = log_pr.index[-87841]\n",
    "log_pr_train = log_pr[:t_train]\n",
    "volu_train = volu[:t_train]\n",
    "\n",
    "x_begin_idx = 30\n",
    "x_end_idx = -30\n",
    "y_begin_idx = 60\n",
    "\n",
    "# grp_idx = {0:[1,5,6,8], 1:[2,4,7], 2:[0,3,9]}\n",
    "feature_dict = get_feature_train(log_pr_train, volu_train, x_begin_idx, x_end_idx, y_begin_idx, grp_idx=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57d879c1bab31ddce3f98747a90aac1ecdf0d747d4f9b6f921c92f41b19b21c9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
